{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.compiler.tensorrt import trt_convert as trt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU') memory growth: True\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    for device in physical_devices:\n",
    "        tf.config.experimental.set_memory_growth(device, True)\n",
    "        print('{} memory growth: {}'.format(device, tf.config.experimental.get_memory_growth(device)))\n",
    "else:\n",
    "    print(\"Not enough GPU hardware devices available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_BASE_PATH = '/workspace/models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MobileNetV2Model(tf.keras.Model):\n",
    "    def __init__(self, name: str):\n",
    "        shape = (224, 224, 3)\n",
    "        base_model = tf.keras.applications.MobileNetV2(input_shape=shape, include_top=True, weights='imagenet')\n",
    "        inputs = tf.keras.Input(shape)\n",
    "        outputs = base_model(inputs)\n",
    "        \n",
    "        super().__init__(inputs=inputs, outputs=outputs, name=name)\n",
    "\n",
    "    @tf.function(\n",
    "        input_signature=[tf.TensorSpec(shape=[None, 224, 224, 3], dtype=tf.float32, name=\"imgs\")]\n",
    "    )\n",
    "    def serving_fn(self, imgs: tf.Tensor) -> tf.Tensor:\n",
    "        return self(imgs)\n",
    "\n",
    "    def save(self):\n",
    "        tf_saved_model_path = os.path.join(MODEL_BASE_PATH, self.name, '0')\n",
    "        \n",
    "        signatures = {\"serving_default\": self.serving_fn}\n",
    "        tf.saved_model.save(self, tf_saved_model_path, signatures=signatures)\n",
    "        \n",
    "        params = trt.DEFAULT_TRT_CONVERSION_PARAMS._replace(\n",
    "            precision_mode=trt.TrtPrecisionMode.FP16,\n",
    "            max_batch_size=10\n",
    "        )\n",
    "        converter = trt.TrtGraphConverterV2(input_saved_model_dir=tf_saved_model_path, conversion_params=params)\n",
    "        converter.convert()\n",
    "        converter.save(os.path.join(MODEL_BASE_PATH, '{}_trt'.format(model.name), '0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224.h5\n",
      "14540800/14536120 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "model = MobileNetV2Model('test1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/test1/0/assets\n",
      "INFO:tensorflow:Linked TensorRT version: (7, 1, 3)\n",
      "INFO:tensorflow:Loaded TensorRT version: (7, 1, 3)\n",
      "INFO:tensorflow:Could not find TRTEngineOp_0_0 in TF-TRT cache. This can happen if build() is not called, which means TensorRT engines will be built and cached at runtime.\n",
      "INFO:tensorflow:Assets written to: ../models/test1_trt/0/assets\n"
     ]
    }
   ],
   "source": [
    "model.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/models/yolov3.h5\r\n"
     ]
    }
   ],
   "source": [
    "!ls /workspace/models/*.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLOV3Model(tf.keras.Model):\n",
    "    def __init__(self, name: str, path: str):\n",
    "        self.input_height = 608\n",
    "        self.input_width = 608\n",
    "        \n",
    "        self.num_classes = 80\n",
    "        \n",
    "        self.anchors = tf.constant([\n",
    "            [\n",
    "                [10, 13],\n",
    "                [16, 30],\n",
    "                [33, 23]\n",
    "            ], [\n",
    "                [30, 61],\n",
    "                [62, 45],\n",
    "                [59, 119]\n",
    "            ], [\n",
    "                [116, 90],\n",
    "                [156, 198],\n",
    "                [373, 326],\n",
    "            ]\n",
    "        ], dtype=tf.float32)\n",
    "        \n",
    "        shape = (self.input_height, self.input_width, 3)\n",
    "        base_model = tf.keras.models.load_model(path)\n",
    "        inputs = tf.keras.Input(shape)\n",
    "        outputs = base_model(inputs)\n",
    "        \n",
    "        super().__init__(inputs=inputs, outputs=outputs, name=name)\n",
    "    \n",
    "    @tf.function\n",
    "    def decode(self, output: tf.Tensor, anchor: tf.Tensor):\n",
    "        batch_size = tf.shape(output)[0]\n",
    "        output_height = tf.shape(output)[1]\n",
    "        output_width = tf.shape(output)[2]\n",
    "\n",
    "        output = tf.reshape(output, (batch_size, output_height, output_width, 3, 5 + self.num_classes))\n",
    "\n",
    "        xy_grid = tf.meshgrid(tf.range(output_height), tf.range(output_width))\n",
    "        xy_grid = tf.stack(xy_grid, -1)[:, :, tf.newaxis]\n",
    "        xy_grid = tf.tile(xy_grid[tf.newaxis, ...], [batch_size, 1, 1, 3, 1])\n",
    "\n",
    "        xy_grid = tf.cast(xy_grid, tf.float32)\n",
    "\n",
    "        dxdy_activated = tf.sigmoid(output[:, :, :, :, :2])\n",
    "        dwdh = output[:, :, :, :, 2:4]\n",
    "        \n",
    "        xy = ((dxdy_activated - 0.5) + xy_grid + 0.5) / tf.cast([output_width, output_height], tf.float32)\n",
    "        wh_half = tf.exp(dwdh) * anchor / (2 * tf.cast([self.input_width, self.input_height], tf.float32))\n",
    "\n",
    "        output = tf.concat(\n",
    "            [\n",
    "                xy - wh_half,\n",
    "                xy + wh_half,\n",
    "                tf.sigmoid(output[:, :, :, :, 4:]),\n",
    "            ], -1\n",
    "        )\n",
    "\n",
    "        return tf.reshape(output, (batch_size, -1, 4 + 1 + self.num_classes))\n",
    "\n",
    "    @tf.function(\n",
    "        input_signature=[tf.TensorSpec(shape=[None, 608, 608, 3], dtype=tf.float32, name=\"imgs\")]\n",
    "    )\n",
    "    def serving_fn(self, imgs: tf.Tensor) -> tf.Tensor:\n",
    "        l, s, m = self(imgs)\n",
    "        \n",
    "        s = self.decode(s, self.anchors[0])\n",
    "        m = self.decode(m, self.anchors[1])\n",
    "        l = self.decode(l, self.anchors[2])\n",
    "        \n",
    "        res = tf.concat((s, m, l), 1)\n",
    "        \n",
    "        boxes, confidences, class_probabilities = tf.split(res, [4, 1, self.num_classes], -1)\n",
    "        \n",
    "        scores = confidences * class_probabilities\n",
    "        \n",
    "        return tf.image.combined_non_max_suppression(\n",
    "            tf.reshape(boxes, (tf.shape(boxes)[0], -1, 1, 4)), scores,\n",
    "            50, 50,\n",
    "            0.5, 0.4,\n",
    "            clip_boxes=False\n",
    "        )\n",
    "\n",
    "    def save(self):\n",
    "        tf_saved_model_path = os.path.join(MODEL_BASE_PATH, self.name, '0')\n",
    "        \n",
    "        signatures = {\"serving_default\": self.serving_fn}\n",
    "        tf.saved_model.save(self, tf_saved_model_path, signatures=signatures)\n",
    "        \n",
    "        params = trt.DEFAULT_TRT_CONVERSION_PARAMS._replace(\n",
    "            precision_mode=trt.TrtPrecisionMode.FP16,\n",
    "            max_batch_size=10\n",
    "        )\n",
    "        converter = trt.TrtGraphConverterV2(input_saved_model_dir=tf_saved_model_path, conversion_params=params)\n",
    "        converter.convert()\n",
    "        converter.save(os.path.join(MODEL_BASE_PATH, '{}_trt'.format(model.name), '0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "model = YOLOV3Model('yolov3', os.path.join(MODEL_BASE_PATH, 'yolov3.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.random.uniform((2, 608, 608, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CombinedNonMaxSuppression(nmsed_boxes=<tf.Tensor: shape=(2, 50, 4), dtype=float32, numpy=\n",
       "array([[[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]]], dtype=float32)>, nmsed_scores=<tf.Tensor: shape=(2, 50), dtype=float32, numpy=\n",
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]], dtype=float32)>, nmsed_classes=<tf.Tensor: shape=(2, 50), dtype=float32, numpy=\n",
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]], dtype=float32)>, valid_detections=<tf.Tensor: shape=(2,), dtype=int32, numpy=array([0, 0], dtype=int32)>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.serving_fn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /workspace/models/yolov3/0/assets\n",
      "INFO:tensorflow:Linked TensorRT version: (7, 1, 3)\n",
      "INFO:tensorflow:Loaded TensorRT version: (7, 1, 3)\n",
      "INFO:tensorflow:Could not find TRTEngineOp_1_2 in TF-TRT cache. This can happen if build() is not called, which means TensorRT engines will be built and cached at runtime.\n",
      "INFO:tensorflow:Could not find TRTEngineOp_1_0 in TF-TRT cache. This can happen if build() is not called, which means TensorRT engines will be built and cached at runtime.\n",
      "INFO:tensorflow:Could not find TRTEngineOp_1_13 in TF-TRT cache. This can happen if build() is not called, which means TensorRT engines will be built and cached at runtime.\n",
      "INFO:tensorflow:Could not find TRTEngineOp_1_1 in TF-TRT cache. This can happen if build() is not called, which means TensorRT engines will be built and cached at runtime.\n",
      "INFO:tensorflow:Could not find TRTEngineOp_1_5 in TF-TRT cache. This can happen if build() is not called, which means TensorRT engines will be built and cached at runtime.\n",
      "INFO:tensorflow:Could not find TRTEngineOp_1_11 in TF-TRT cache. This can happen if build() is not called, which means TensorRT engines will be built and cached at runtime.\n",
      "INFO:tensorflow:Could not find TRTEngineOp_1_14 in TF-TRT cache. This can happen if build() is not called, which means TensorRT engines will be built and cached at runtime.\n",
      "INFO:tensorflow:Could not find TRTEngineOp_1_12 in TF-TRT cache. This can happen if build() is not called, which means TensorRT engines will be built and cached at runtime.\n",
      "INFO:tensorflow:Could not find TRTEngineOp_1_9 in TF-TRT cache. This can happen if build() is not called, which means TensorRT engines will be built and cached at runtime.\n",
      "INFO:tensorflow:Could not find TRTEngineOp_1_3 in TF-TRT cache. This can happen if build() is not called, which means TensorRT engines will be built and cached at runtime.\n",
      "INFO:tensorflow:Could not find TRTEngineOp_1_6 in TF-TRT cache. This can happen if build() is not called, which means TensorRT engines will be built and cached at runtime.\n",
      "INFO:tensorflow:Could not find TRTEngineOp_1_4 in TF-TRT cache. This can happen if build() is not called, which means TensorRT engines will be built and cached at runtime.\n",
      "INFO:tensorflow:Could not find TRTEngineOp_1_7 in TF-TRT cache. This can happen if build() is not called, which means TensorRT engines will be built and cached at runtime.\n",
      "INFO:tensorflow:Could not find TRTEngineOp_1_10 in TF-TRT cache. This can happen if build() is not called, which means TensorRT engines will be built and cached at runtime.\n",
      "INFO:tensorflow:Could not find TRTEngineOp_1_8 in TF-TRT cache. This can happen if build() is not called, which means TensorRT engines will be built and cached at runtime.\n",
      "INFO:tensorflow:Could not find TRTEngineOp_1_15 in TF-TRT cache. This can happen if build() is not called, which means TensorRT engines will be built and cached at runtime.\n",
      "INFO:tensorflow:Assets written to: /workspace/models/yolov3_trt/0/assets\n"
     ]
    }
   ],
   "source": [
    "model.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = tf.image.decode_image(tf.io.read_file('sf.jpg'), 3)\n",
    "img_letter_box = tf.image.resize_with_pad(img, 608, 608)\n",
    "img_normalized = img_letter_box / 255.0\n",
    "imgs = img_normalized[tf.newaxis, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CombinedNonMaxSuppression(nmsed_boxes=<tf.Tensor: shape=(1, 50, 4), dtype=float32, numpy=\n",
       "array([[[ 0.74796623,  0.75367075,  0.99423736,  0.8824597 ],\n",
       "        [ 0.6754285 ,  0.7606683 ,  0.7079605 ,  0.8015331 ],\n",
       "        [ 0.59259444,  0.78136146,  0.6032229 ,  0.80154324],\n",
       "        [ 0.5949346 ,  0.7775313 ,  0.6050073 ,  0.7981953 ],\n",
       "        [ 0.5222986 ,  0.7841931 ,  0.53417575,  0.8026394 ],\n",
       "        [ 0.630662  ,  0.73028594,  0.7259639 ,  0.84273535],\n",
       "        [-0.02498848,  0.7493981 ,  0.0684564 ,  0.87260294],\n",
       "        [ 0.04682338,  0.75067437,  0.15263286,  0.87288594],\n",
       "        [ 0.4735718 ,  0.72715735,  0.59456336,  0.7666298 ],\n",
       "        [ 0.44052532,  0.61213034,  0.5255808 ,  0.6901886 ],\n",
       "        [ 0.51553476,  0.7402755 ,  0.62544334,  0.8489164 ],\n",
       "        [ 0.5482995 ,  0.7234647 ,  0.65252763,  0.85085964],\n",
       "        [ 0.49022123,  0.6886039 ,  0.57789904,  0.8040917 ],\n",
       "        [ 0.5175544 ,  0.7837814 ,  0.53068054,  0.8029568 ],\n",
       "        [ 0.09577223,  0.80272686,  0.10655392,  0.82039535],\n",
       "        [ 0.14381744,  0.800805  ,  0.15626962,  0.8182391 ],\n",
       "        [ 0.00222374,  0.76219904,  0.12072984,  0.8655366 ],\n",
       "        [ 0.47697827,  0.7285899 ,  0.5838007 ,  0.860201  ],\n",
       "        [ 0.05768846,  0.8047489 ,  0.07034767,  0.8211905 ],\n",
       "        [ 0.01093236,  0.802045  ,  0.02171282,  0.8203212 ],\n",
       "        [ 0.10768694,  0.75407636,  0.19951198,  0.87133837],\n",
       "        [ 0.34468886,  0.68918455,  0.3812717 ,  0.83112013],\n",
       "        [ 0.32747498,  0.73210454,  0.40167788,  0.79095924],\n",
       "        [ 0.66590166,  0.7613924 ,  0.69415283,  0.7991944 ],\n",
       "        [ 0.5647238 ,  0.78447497,  0.5764995 ,  0.8013077 ],\n",
       "        [ 0.9232426 ,  0.7567369 ,  1.04355   ,  0.81169474],\n",
       "        [ 0.4597845 ,  0.6930093 ,  0.5459478 ,  0.78271514],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ]]],\n",
       "      dtype=float32)>, nmsed_scores=<tf.Tensor: shape=(1, 50), dtype=float32, numpy=\n",
       "array([[0.99865437, 0.9889525 , 0.97325546, 0.9730736 , 0.966602  ,\n",
       "        0.9665954 , 0.9327227 , 0.9323338 , 0.93130994, 0.92708224,\n",
       "        0.9246742 , 0.9095623 , 0.8846505 , 0.87129146, 0.86904216,\n",
       "        0.84275824, 0.83772486, 0.80194837, 0.7907575 , 0.77645445,\n",
       "        0.71999055, 0.7099373 , 0.6345181 , 0.6149924 , 0.56202316,\n",
       "        0.5147579 , 0.433928  , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ]],\n",
       "      dtype=float32)>, nmsed_classes=<tf.Tensor: shape=(1, 50), dtype=float32, numpy=\n",
       "array([[2., 2., 0., 0., 0., 0., 0., 0., 2., 9., 0., 0., 2., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 2., 0., 0., 2., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]], dtype=float32)>, valid_detections=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([27], dtype=int32)>)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.serving_fn(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
